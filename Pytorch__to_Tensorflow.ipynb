{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAQedXuJrO5khVQSwifce5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dinhthixuanbinh/ONNx_demo/blob/main/Pytorch__to_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfwNdYXgADky",
        "outputId": "6f14d3d5-3824-44f0-eb43-9d774652fae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Cloning into 'onnx-tensorflow'...\n",
            "remote: Enumerating objects: 6516, done.\u001b[K\n",
            "remote: Counting objects: 100% (465/465), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 6516 (delta 326), reused 383 (delta 261), pack-reused 6051\u001b[K\n",
            "Receiving objects: 100% (6516/6516), 1.98 MiB | 2.72 MiB/s, done.\n",
            "Resolving deltas: 100% (5051/5051), done.\n",
            "Obtaining file:///content/onnx-tensorflow\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (6.0.1)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.23.0)\n",
            "Requirement already satisfied: tensorflow_probability in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (23.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (2.13.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.1.8)\n",
            "Requirement already satisfied: typing-extensions<4.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.5.0)\n",
            "Installing collected packages: onnx-tf\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnx-tensorflow (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnx-tensorflow\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install tensorflow-addons\n",
        "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e .\n",
        "!pip install torchvision\n",
        "!pip install onnx-tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import onnx\n",
        "from onnx import backend\n",
        ""
      ],
      "metadata": {
        "id": "NVLTs6rkAXfQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "oJgXUjiABBdC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
        "                    epoch,  loss.item()))"
      ],
      "metadata": {
        "id": "Z8qkoEfoDKtq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "ns-JvDb3DPLW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=1000, shuffle=True)\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "for epoch in range(21):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMv0DIYkDQ0o",
        "outputId": "b38d717d-9a41-4672-a976-058bbbb7130d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 257595841.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 44453465.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 71286090.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15757261.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Train Epoch: 0 \tLoss: 2.327492\n",
            "\n",
            "Test set: Average loss: 0.2007, Accuracy: 9421/10000 (94%)\n",
            "\n",
            "Train Epoch: 1 \tLoss: 0.416417\n",
            "\n",
            "Test set: Average loss: 0.1218, Accuracy: 9621/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.215019\n",
            "\n",
            "Test set: Average loss: 0.0978, Accuracy: 9689/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.409411\n",
            "\n",
            "Test set: Average loss: 0.0831, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 \tLoss: 0.178752\n",
            "\n",
            "Test set: Average loss: 0.0750, Accuracy: 9766/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 \tLoss: 0.120448\n",
            "\n",
            "Test set: Average loss: 0.0665, Accuracy: 9784/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 \tLoss: 0.194846\n",
            "\n",
            "Test set: Average loss: 0.0601, Accuracy: 9816/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 \tLoss: 0.272399\n",
            "\n",
            "Test set: Average loss: 0.0580, Accuracy: 9820/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 \tLoss: 0.201344\n",
            "\n",
            "Test set: Average loss: 0.0545, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 \tLoss: 0.088901\n",
            "\n",
            "Test set: Average loss: 0.0530, Accuracy: 9846/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 \tLoss: 0.185910\n",
            "\n",
            "Test set: Average loss: 0.0482, Accuracy: 9842/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 \tLoss: 0.285652\n",
            "\n",
            "Test set: Average loss: 0.0447, Accuracy: 9863/10000 (99%)\n",
            "\n",
            "Train Epoch: 12 \tLoss: 0.150625\n",
            "\n",
            "Test set: Average loss: 0.0460, Accuracy: 9858/10000 (99%)\n",
            "\n",
            "Train Epoch: 13 \tLoss: 0.044089\n",
            "\n",
            "Test set: Average loss: 0.0427, Accuracy: 9865/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 \tLoss: 0.198683\n",
            "\n",
            "Test set: Average loss: 0.0418, Accuracy: 9872/10000 (99%)\n",
            "\n",
            "Train Epoch: 15 \tLoss: 0.130353\n",
            "\n",
            "Test set: Average loss: 0.0422, Accuracy: 9864/10000 (99%)\n",
            "\n",
            "Train Epoch: 16 \tLoss: 0.180496\n",
            "\n",
            "Test set: Average loss: 0.0384, Accuracy: 9889/10000 (99%)\n",
            "\n",
            "Train Epoch: 17 \tLoss: 0.052850\n",
            "\n",
            "Test set: Average loss: 0.0384, Accuracy: 9886/10000 (99%)\n",
            "\n",
            "Train Epoch: 18 \tLoss: 0.281299\n",
            "\n",
            "Test set: Average loss: 0.0412, Accuracy: 9871/10000 (99%)\n",
            "\n",
            "Train Epoch: 19 \tLoss: 0.179773\n",
            "\n",
            "Test set: Average loss: 0.0370, Accuracy: 9882/10000 (99%)\n",
            "\n",
            "Train Epoch: 20 \tLoss: 0.099104\n",
            "\n",
            "Test set: Average loss: 0.0369, Accuracy: 9890/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'mnist.pth')\n"
      ],
      "metadata": {
        "id": "LkUu5p8VDUfD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = Net()\n",
        "trained_model.load_state_dict(torch.load('mnist.pth'))\n",
        "\n",
        "dummy_input = Variable(torch.randn(1, 1, 28, 28))\n",
        "torch.onnx.export(trained_model, dummy_input, \"mnist.onnx\")\n"
      ],
      "metadata": {
        "id": "zKWPxVojDgTo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/onnx/onnx-tensorflow.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR_mCEwXF22Y",
        "outputId": "0917f728-7402-413e-c4c3-7b7b84a6b7c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/onnx/onnx-tensorflow.git\n",
            "  Cloning https://github.com/onnx/onnx-tensorflow.git to /tmp/pip-req-build-emnqocur\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/onnx/onnx-tensorflow.git /tmp/pip-req-build-emnqocur\n",
            "  Resolved https://github.com/onnx/onnx-tensorflow.git to commit ee0c5e537b3cebbddc5773871e6786e6468c7f3f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (6.0.1)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.23.0)\n",
            "Requirement already satisfied: tensorflow_probability in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (23.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (2.13.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.1.8)\n",
            "Requirement already satisfied: typing-extensions<4.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.5.0)\n",
            "Building wheels for collected packages: onnx-tf\n",
            "  Building wheel for onnx-tf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-tf: filename=onnx_tf-1.10.0-py3-none-any.whl size=226641 sha256=786f201807548b2126e08528e47526bc8559927cf72f4440c2078c345c07c01a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-go_xi2mi/wheels/26/8d/09/2c2cfa55123a5633aae58e44c4c6baf908c7f2e75470e0f392\n",
            "Successfully built onnx-tf\n",
            "Installing collected packages: onnx-tf\n",
            "  Attempting uninstall: onnx-tf\n",
            "    Found existing installation: onnx-tf 1.10.0\n",
            "    Uninstalling onnx-tf-1.10.0:\n",
            "      Successfully uninstalled onnx-tf-1.10.0\n",
            "Successfully installed onnx-tf-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnx_tf.backend import prepare\n",
        "\n",
        "# Load the ONNX file\n",
        "model = onnx.load('mnist.onnx')\n",
        "\n",
        "# Import the ONNX model to Tensorflow\n",
        "tf_rep = prepare(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJpJgNxYDkWy",
        "outputId": "0a54ee20-5167-4458-ed89-7fcbec0bec39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "tf_rep.export_graph('mnist.pb')\n"
      ],
      "metadata": {
        "id": "4I5ZdayQGF0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Image 1:')\n",
        "img = Image.open('/content/img1.png').resize((28, 28)).convert('L')\n",
        "display(img)\n",
        "output = tf_rep.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
        "print('The digit is classified as ', np.argmax(output))\n",
        "print('------------------------------------------------------------------------------')\n",
        "print('Image 2:')\n",
        "img = Image.open('/content/img2.png').resize((28, 28)).convert('L')\n",
        "display(img)\n",
        "output = tf_rep.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
        "print('The digit is classified as ', np.argmax(output))"
      ],
      "metadata": {
        "id": "lwvSgiZTDnbt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}